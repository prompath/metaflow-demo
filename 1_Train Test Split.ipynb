{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92b4502-3948-41ea-ba24-d20670814f6f",
   "metadata": {},
   "source": [
    "# Load and Split Data Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87bf1ad-1e1d-44fa-8e42-ad205d3df0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T17:04:59.331965Z",
     "iopub.status.busy": "2025-02-22T17:04:59.330744Z",
     "iopub.status.idle": "2025-02-22T17:05:08.115257Z",
     "shell.execute_reply": "2025-02-22T17:05:08.114790Z",
     "shell.execute_reply.started": "2025-02-22T17:04:59.331902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.13.9 executing DataLoaderFlow for user:jeera\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint is happy!\n",
      "2025-02-23 00:05:03.630 Workflow starting (run-id 1740243903630317):\n",
      "2025-02-23 00:05:03.641 [1740243903630317/start/1 (pid 86826)] Task is starting.\n",
      "2025-02-23 00:05:04.290 [1740243903630317/start/1 (pid 86826)] Running data loading and splitting flow...\n",
      "2025-02-23 00:05:04.380 [1740243903630317/start/1 (pid 86826)] Task finished successfully.\n",
      "2025-02-23 00:05:04.386 [1740243903630317/load/2 (pid 86829)] Task is starting.\n",
      "2025-02-23 00:05:05.069 [1740243903630317/load/2 (pid 86829)] Task finished successfully.\n",
      "2025-02-23 00:05:05.075 [1740243903630317/split/3 (pid 86832)] Task is starting.\n",
      "2025-02-23 00:05:05.763 [1740243903630317/split/3 (pid 86832)] Task finished successfully.\n",
      "2025-02-23 00:05:05.769 [1740243903630317/persist/4 (pid 86835)] Task is starting.\n",
      "2025-02-23 00:05:06.461 [1740243903630317/persist/4 (pid 86835)] Task finished successfully.\n",
      "2025-02-23 00:05:06.467 [1740243903630317/end/5 (pid 86838)] Task is starting.\n",
      "2025-02-23 00:05:07.105 [1740243903630317/end/5 (pid 86838)] Split dataset saved to ./data\n",
      "2025-02-23 00:05:07.108 [1740243903630317/end/5 (pid 86838)] Shape of saved train set (120, 4)\n",
      "2025-02-23 00:05:07.109 [1740243903630317/end/5 (pid 86838)] Shape of saved test set (30, 4)\n",
      "2025-02-23 00:05:07.191 [1740243903630317/end/5 (pid 86838)] Task finished successfully.\n",
      "2025-02-23 00:05:07.191 Done!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from metaflow import FlowSpec, Parameter, step, NBRunner\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class DataLoaderFlow(FlowSpec):\n",
    "    test_size = Parameter(\n",
    "        name=\"test_size\",\n",
    "        help=\"Ratio of test set\",\n",
    "        default=0.2\n",
    "    )\n",
    "    random_state = Parameter(\n",
    "        name=\"random_state\",\n",
    "        help=\"Random seed\",\n",
    "        default=42\n",
    "    )\n",
    "    dataset_dir = Parameter(\n",
    "        name=\"dataset_dir\",\n",
    "        help=\"Path to save the splits\",\n",
    "        default=\"./data\"\n",
    "    )\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.dataset_path = Path(self.dataset_dir).resolve()\n",
    "        print(\"Running data loading and splitting flow...\")\n",
    "        self.next(self.load)\n",
    "\n",
    "    @step\n",
    "    def load(self):\n",
    "        self.dataset = load_iris()\n",
    "        self.next(self.split)\n",
    "\n",
    "    @step\n",
    "    def split(self):\n",
    "        X = self.dataset[\"data\"]\n",
    "        y = self.dataset[\"target\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, \n",
    "            y, \n",
    "            test_size=self.test_size, \n",
    "            random_state=self.random_state, \n",
    "            stratify=y\n",
    "        )\n",
    "        self.train = pd.DataFrame(X_train, columns=self.dataset[\"feature_names\"])\n",
    "        self.train[\"target\"] = y_train\n",
    "        self.test = pd.DataFrame(X_test, columns=self.dataset[\"feature_names\"])\n",
    "        self.test[\"target\"] = y_test\n",
    "        self.next(self.persist)\n",
    "\n",
    "    @step\n",
    "    def persist(self):\n",
    "        self.dataset_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.train.to_csv(self.dataset_path / \"train.csv\", index=False)\n",
    "        self.test.to_csv(self.dataset_path / \"test.csv\", index=False)\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(f\"Split dataset saved to {self.dataset_dir}\")\n",
    "        print(f\"Shape of saved train set {self.train.drop(columns='target').shape}\")\n",
    "        print(f\"Shape of saved test set {self.test.drop(columns='target').shape}\")\n",
    "\n",
    "\n",
    "run = NBRunner(DataLoaderFlow, base_dir=\"./artifacts\").nbrun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810520c-b614-4534-b541-ac906881006c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
